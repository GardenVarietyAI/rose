[project]
name = "rose-server"
version = "0.1.3"
description = "ROSE Server - Run your own LLM server"
readme = "README.md"
requires-python = ">=3.12,<4.0"
authors = [{ name = "Garden Variety AI" }]
license = { text = "MIT" }
keywords = ["llm", "ai", "openai", "inference", "server"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.12",
]
dependencies = [
    "fastapi>=0.110.0",
    "uvicorn>=0.27.1",
    "pydantic~=2.11.7",
    "numpy>=1.26.4",
    "fastembed-qwen3>=0.7.3.post3",
    "pydantic-settings>=2.9.1",
    "openai>=1.88.0",
    "openai-agents>=0.0.19",
    "sqlalchemy>=2.0.0",
    "sqlmodel>=0.0.24",
    "sse-starlette>=2.1.3",
    "aiosqlite>=0.21.0",
    "greenlet>=3.2.2",
    "aiofiles>=24.1.0",
    "python-multipart>=0.0.18",
    "tokenizers>=0.21.2",
    "sqlite-vec>=0.1.6",
    "chonkie[tokenizers]~=1.1.2",
    "pypdf>=6.0.0",
    "jinja2>=3.1.6",
    "safetensors>=0.6.2",
    "onnxruntime>=1.21.0",
    "rose-inference-rs @ file:///${PROJECT_ROOT}/packages/rose-inference-rs",
]

[project.scripts]
rose-server = "rose_server.main:main"

[build-system]
requires = ["hatchling", "maturin>=1.9.0"]
build-backend = "hatchling.build"

[tool.hatch.build]
packages = ["src/rose_server"]
